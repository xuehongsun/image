{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nfrom numpy import asarray\nimport tensorflow as tf\nimport tensorflow_datasets as tfds\nimport glob\nimport matplotlib.pyplot as plt\nimport PIL\nfrom PIL import Image\nimport os\nfrom sklearn.model_selection import StratifiedKFold\nimport pathlib","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-25T16:40:02.520815Z","iopub.execute_input":"2022-02-25T16:40:02.521176Z","iopub.status.idle":"2022-02-25T16:40:02.527255Z","shell.execute_reply.started":"2022-02-25T16:40:02.521145Z","shell.execute_reply":"2022-02-25T16:40:02.526168Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"#count total number of images\ndata_dir = pathlib.Path(\"../input/vehicleImage/vehicles\")\nimage_count = len(list(data_dir.glob('*/*.JPEG')))\nprint(image_count)\n\n#get the list of names of all the images and shuffle\nlist_ds = tf.data.Dataset.list_files(\"../input/vehicleImage/vehicles/*/*\", shuffle=False)\nlist_ds = list_ds.shuffle(image_count, reshuffle_each_iteration=False)","metadata":{"execution":{"iopub.status.busy":"2022-02-25T16:46:05.659313Z","iopub.execute_input":"2022-02-25T16:46:05.659653Z","iopub.status.idle":"2022-02-25T16:46:07.849572Z","shell.execute_reply.started":"2022-02-25T16:46:05.659618Z","shell.execute_reply":"2022-02-25T16:46:07.848580Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"for f in list_ds.take(4):\n  print(f.numpy())","metadata":{"execution":{"iopub.status.busy":"2022-02-25T16:52:25.669255Z","iopub.execute_input":"2022-02-25T16:52:25.669604Z","iopub.status.idle":"2022-02-25T16:52:25.693566Z","shell.execute_reply.started":"2022-02-25T16:52:25.669555Z","shell.execute_reply":"2022-02-25T16:52:25.692560Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"#The tree structure of the files can be used to compile a class_names list.\nclass_names = np.array(sorted([item.name for item in data_dir.glob('*')]))\nprint(class_names)","metadata":{"execution":{"iopub.status.busy":"2022-02-25T16:53:56.522394Z","iopub.execute_input":"2022-02-25T16:53:56.523133Z","iopub.status.idle":"2022-02-25T16:53:56.531310Z","shell.execute_reply.started":"2022-02-25T16:53:56.523097Z","shell.execute_reply":"2022-02-25T16:53:56.530309Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"#Split the dataset into training and validation sets:\nval_size = int(image_count * 0.2)\ntrain_ds = list_ds.skip(val_size)\nval_ds = list_ds.take(val_size)\nprint(tf.data.experimental.cardinality(train_ds).numpy())\nprint(tf.data.experimental.cardinality(val_ds).numpy())","metadata":{"execution":{"iopub.status.busy":"2022-02-25T17:02:20.512424Z","iopub.execute_input":"2022-02-25T17:02:20.512782Z","iopub.status.idle":"2022-02-25T17:02:20.523137Z","shell.execute_reply.started":"2022-02-25T17:02:20.512749Z","shell.execute_reply":"2022-02-25T17:02:20.522026Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# functions that convert a file path to an (img, label) pair:\nbatch_size = 32\nimg_height = 500\nimg_width = 500\n\ndef get_label(file_path):\n  # Convert the path to a list of path components\n  parts = tf.strings.split(file_path, os.path.sep)\n  # The second to last is the class-directory\n  one_hot = parts[-2] == class_names\n  # Integer encode the label\n  return tf.argmax(one_hot)\n\ndef decode_img(img):\n  # Convert the compressed string to a 3D uint8 tensor\n  img = tf.io.decode_jpeg(img, channels=3)\n  # Resize the image to the desired size\n  return tf.image.resize(img, [img_height, img_width])\n\ndef process_path(file_path):\n  label = get_label(file_path)\n  # Load the raw data from the file as a string\n  img = tf.io.read_file(file_path)\n  img = decode_img(img)\n  return img, label","metadata":{"execution":{"iopub.status.busy":"2022-02-25T17:08:58.582685Z","iopub.execute_input":"2022-02-25T17:08:58.582986Z","iopub.status.idle":"2022-02-25T17:08:58.593474Z","shell.execute_reply.started":"2022-02-25T17:08:58.582954Z","shell.execute_reply":"2022-02-25T17:08:58.592394Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"# Use Dataset.map to create a dataset of image, label pairs:\n# Set `num_parallel_calls` so multiple images are loaded/processed in parallel.\nAUTOTUNE = tf.data.AUTOTUNE\ntrain_ds = train_ds.map(process_path, num_parallel_calls=AUTOTUNE)\nval_ds = val_ds.map(process_path, num_parallel_calls=AUTOTUNE)","metadata":{"execution":{"iopub.status.busy":"2022-02-25T17:09:03.185754Z","iopub.execute_input":"2022-02-25T17:09:03.186050Z","iopub.status.idle":"2022-02-25T17:09:03.461137Z","shell.execute_reply.started":"2022-02-25T17:09:03.186018Z","shell.execute_reply":"2022-02-25T17:09:03.460082Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"for image, label in train_ds.take(1):\n  print(\"Image shape: \", image.numpy().shape)\n  print(\"Label: \", label.numpy())","metadata":{"execution":{"iopub.status.busy":"2022-02-25T17:10:46.537318Z","iopub.execute_input":"2022-02-25T17:10:46.538498Z","iopub.status.idle":"2022-02-25T17:10:46.718313Z","shell.execute_reply.started":"2022-02-25T17:10:46.538448Z","shell.execute_reply":"2022-02-25T17:10:46.716857Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"#Configure dataset for performance\n#To be well shuffled.\n#To be batched.\n#Batches to be available as soon as possible.\n\ndef configure_for_performance(ds):\n  ds = ds.cache()\n  ds = ds.shuffle(buffer_size=1000)\n  ds = ds.batch(batch_size)\n  ds = ds.prefetch(buffer_size=AUTOTUNE)\n  return ds\n\ntrain_ds = configure_for_performance(train_ds)\nval_ds = configure_for_performance(val_ds)","metadata":{"execution":{"iopub.status.busy":"2022-02-25T17:12:12.088503Z","iopub.execute_input":"2022-02-25T17:12:12.088845Z","iopub.status.idle":"2022-02-25T17:12:12.103560Z","shell.execute_reply.started":"2022-02-25T17:12:12.088812Z","shell.execute_reply":"2022-02-25T17:12:12.102586Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"#Visualize the data\nimage_batch, label_batch = next(iter(train_ds))\n\nplt.figure(figsize=(10, 10))\nfor i in range(9):\n  ax = plt.subplot(3, 3, i + 1)\n  plt.imshow(image_batch[i].numpy().astype(\"uint8\"))\n  label = label_batch[i]\n  plt.title(class_names[label])\n  plt.axis(\"off\")","metadata":{"execution":{"iopub.status.busy":"2022-02-25T17:16:10.342024Z","iopub.execute_input":"2022-02-25T17:16:10.342346Z","iopub.status.idle":"2022-02-25T17:16:17.723088Z","shell.execute_reply.started":"2022-02-25T17:16:10.342315Z","shell.execute_reply":"2022-02-25T17:16:17.720596Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"num_classes = 10\n\nmodel = tf.keras.Sequential([\n  tf.keras.layers.Rescaling(1./255),\n  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n  tf.keras.layers.MaxPooling2D(),\n  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n  tf.keras.layers.MaxPooling2D(),\n  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n  tf.keras.layers.MaxPooling2D(),\n  tf.keras.layers.Flatten(),\n  tf.keras.layers.Dense(128, activation='relu'),\n  tf.keras.layers.Dense(num_classes)\n])","metadata":{"execution":{"iopub.status.busy":"2022-02-25T17:21:07.797351Z","iopub.execute_input":"2022-02-25T17:21:07.797655Z","iopub.status.idle":"2022-02-25T17:21:07.820946Z","shell.execute_reply.started":"2022-02-25T17:21:07.797625Z","shell.execute_reply":"2022-02-25T17:21:07.819946Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"model.compile(\n  optimizer='adam',\n  loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n  metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-02-25T17:21:41.799191Z","iopub.execute_input":"2022-02-25T17:21:41.799455Z","iopub.status.idle":"2022-02-25T17:21:41.820961Z","shell.execute_reply.started":"2022-02-25T17:21:41.799427Z","shell.execute_reply":"2022-02-25T17:21:41.820102Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"#training the model\nmodel.fit(\n  train_ds,\n  validation_data=val_ds,\n  epochs=3\n)\n","metadata":{"execution":{"iopub.status.busy":"2022-02-25T17:21:47.454648Z","iopub.execute_input":"2022-02-25T17:21:47.454965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2022-02-25T16:02:45.994191Z","iopub.execute_input":"2022-02-25T16:02:45.994474Z","iopub.status.idle":"2022-02-25T16:02:46.000064Z","shell.execute_reply.started":"2022-02-25T16:02:45.994447Z","shell.execute_reply":"2022-02-25T16:02:45.999265Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"\n","metadata":{"execution":{"iopub.status.busy":"2022-02-24T23:29:45.677857Z","iopub.execute_input":"2022-02-24T23:29:45.678585Z","iopub.status.idle":"2022-02-24T23:32:25.286542Z","shell.execute_reply.started":"2022-02-24T23:29:45.678542Z","shell.execute_reply":"2022-02-24T23:32:25.285594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=5)\nskf = StratifiedKFold(n_splits=3)\nfor train_index, test_index in skf.split(Images, targets):\n    targets_train, targets_test = np.array(targets)[train_index], np.array(targets)[test_index]\n    Images_train, Images_test = np.array(Images)[train_index], np.array(Images)[test_index]\n    ","metadata":{"execution":{"iopub.status.busy":"2022-02-24T23:33:46.884277Z","iopub.execute_input":"2022-02-24T23:33:46.884988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = tf.data.Dataset.from_tensor_slices((Aircraft_Carrier, labels))\n#dataset = dataset.batch(32)\n#    out_images = np.array(X_train)[indices.astype(int)]\n    ","metadata":{"execution":{"iopub.status.busy":"2022-02-24T23:24:38.787323Z","iopub.execute_input":"2022-02-24T23:24:38.787915Z","iopub.status.idle":"2022-02-24T23:24:38.804219Z","shell.execute_reply.started":"2022-02-24T23:24:38.787883Z","shell.execute_reply":"2022-02-24T23:24:38.802913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2022-02-24T23:23:51.478174Z","iopub.execute_input":"2022-02-24T23:23:51.478911Z","iopub.status.idle":"2022-02-24T23:23:51.483707Z","shell.execute_reply.started":"2022-02-24T23:23:51.478871Z","shell.execute_reply":"2022-02-24T23:23:51.483022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2022-02-24T23:16:56.867485Z","iopub.execute_input":"2022-02-24T23:16:56.867768Z","iopub.status.idle":"2022-02-24T23:16:56.873795Z","shell.execute_reply.started":"2022-02-24T23:16:56.867738Z","shell.execute_reply":"2022-02-24T23:16:56.873023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pyplot.imshow(Images[0])\npyplot.show()\npyplot.imshow(Images[1])\npyplot.show()\npyplot.imshow(Images[2])\npyplot.show()\n","metadata":{"execution":{"iopub.status.busy":"2022-02-24T23:17:28.554397Z","iopub.execute_input":"2022-02-24T23:17:28.554683Z","iopub.status.idle":"2022-02-24T23:17:29.191241Z","shell.execute_reply.started":"2022-02-24T23:17:28.55465Z","shell.execute_reply":"2022-02-24T23:17:29.19046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2022-02-24T23:07:31.042676Z","iopub.execute_input":"2022-02-24T23:07:31.043007Z","iopub.status.idle":"2022-02-24T23:07:31.054737Z","shell.execute_reply.started":"2022-02-24T23:07:31.042973Z","shell.execute_reply":"2022-02-24T23:07:31.054098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_classes = 5\n\nmodel = tf.keras.Sequential([\n  tf.keras.layers.Rescaling(1./255),\n  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n  tf.keras.layers.MaxPooling2D(),\n  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n  tf.keras.layers.MaxPooling2D(),\n  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n  tf.keras.layers.MaxPooling2D(),\n  tf.keras.layers.Flatten(),\n  tf.keras.layers.Dense(128, activation='relu'),\n  tf.keras.layers.Dense(num_classes)\n])","metadata":{"execution":{"iopub.status.busy":"2022-02-24T23:07:34.209536Z","iopub.execute_input":"2022-02-24T23:07:34.20997Z","iopub.status.idle":"2022-02-24T23:07:34.214593Z","shell.execute_reply.started":"2022-02-24T23:07:34.209939Z","shell.execute_reply":"2022-02-24T23:07:34.214078Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(\n  optimizer='adam',\n  loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n  metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-02-24T23:07:36.620731Z","iopub.execute_input":"2022-02-24T23:07:36.621368Z","iopub.status.idle":"2022-02-24T23:07:36.626799Z","shell.execute_reply.started":"2022-02-24T23:07:36.621326Z","shell.execute_reply":"2022-02-24T23:07:36.626143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit(\n  train_ds,\n  validation_data=val_ds,\n  epochs=3\n)","metadata":{"execution":{"iopub.status.busy":"2022-02-24T23:01:44.340372Z","iopub.execute_input":"2022-02-24T23:01:44.340687Z","iopub.status.idle":"2022-02-24T23:01:44.346382Z","shell.execute_reply.started":"2022-02-24T23:01:44.340641Z","shell.execute_reply":"2022-02-24T23:01:44.345607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load and preprocess images\nAircraft_Carrier = []\nfor filename in glob.glob('../input/vehicleImage/vehicles/Aircraft_Carrier/*.JPEG'): #assuming JPEG\n    # load the image and resize\n    im=Image.open(filename).resize((500,500))\n    imRGB=im.convert('RGB')\n    # convert image to numpy array\n    imdata = asarray(imRGB)\n    Aircraft_Carrier.append(imdata)\n    \n    ","metadata":{"execution":{"iopub.status.busy":"2022-02-24T21:28:01.012211Z","iopub.execute_input":"2022-02-24T21:28:01.01291Z","iopub.status.idle":"2022-02-24T21:28:16.55725Z","shell.execute_reply.started":"2022-02-24T21:28:01.012867Z","shell.execute_reply":"2022-02-24T21:28:16.556456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2022-02-24T21:28:20.805461Z","iopub.execute_input":"2022-02-24T21:28:20.805748Z","iopub.status.idle":"2022-02-24T21:28:20.812286Z","shell.execute_reply.started":"2022-02-24T21:28:20.805717Z","shell.execute_reply":"2022-02-24T21:28:20.811271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2022-02-24T21:28:44.977756Z","iopub.execute_input":"2022-02-24T21:28:44.978047Z","iopub.status.idle":"2022-02-24T21:28:45.609124Z","shell.execute_reply.started":"2022-02-24T21:28:44.978011Z","shell.execute_reply":"2022-02-24T21:28:45.608349Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n","metadata":{"execution":{"iopub.status.busy":"2022-02-24T21:31:21.69628Z","iopub.execute_input":"2022-02-24T21:31:21.696666Z","iopub.status.idle":"2022-02-24T21:31:21.700556Z","shell.execute_reply.started":"2022-02-24T21:31:21.696636Z","shell.execute_reply":"2022-02-24T21:31:21.699703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2022-02-24T21:31:53.784295Z","iopub.execute_input":"2022-02-24T21:31:53.784603Z","iopub.status.idle":"2022-02-24T21:43:04.696566Z","shell.execute_reply.started":"2022-02-24T21:31:53.784576Z","shell.execute_reply":"2022-02-24T21:43:04.695425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2022-02-24T21:59:20.458968Z","iopub.execute_input":"2022-02-24T21:59:20.459912Z","iopub.status.idle":"2022-02-24T21:59:20.464218Z","shell.execute_reply.started":"2022-02-24T21:59:20.459863Z","shell.execute_reply":"2022-02-24T21:59:20.463353Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2022-02-24T21:59:24.52828Z","iopub.execute_input":"2022-02-24T21:59:24.528542Z","iopub.status.idle":"2022-02-24T21:59:29.714238Z","shell.execute_reply.started":"2022-02-24T21:59:24.528514Z","shell.execute_reply":"2022-02-24T21:59:29.713202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Original dataset\")\n\n#for i in dataset:   \n#    print(i)","metadata":{"execution":{"iopub.status.busy":"2022-02-24T21:59:29.840116Z","iopub.execute_input":"2022-02-24T21:59:29.840365Z","iopub.status.idle":"2022-02-24T21:59:29.845122Z","shell.execute_reply.started":"2022-02-24T21:59:29.840339Z","shell.execute_reply":"2022-02-24T21:59:29.844491Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n# set aside 20% of train and test data for evaluation\n\nX_train, X_test, y_train, y_test = train_test_split(\nac, lbs, test_size=0.2, random_state=42)\n#np.split(x, 3)\n","metadata":{"execution":{"iopub.status.busy":"2022-02-24T22:06:34.766462Z","iopub.execute_input":"2022-02-24T22:06:34.766808Z","iopub.status.idle":"2022-02-24T22:06:34.772942Z","shell.execute_reply.started":"2022-02-24T22:06:34.766778Z","shell.execute_reply":"2022-02-24T22:06:34.772084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Original dataset\")\ny_test","metadata":{"execution":{"iopub.status.busy":"2022-02-24T22:07:07.829072Z","iopub.execute_input":"2022-02-24T22:07:07.829484Z","iopub.status.idle":"2022-02-24T22:07:07.835909Z","shell.execute_reply.started":"2022-02-24T22:07:07.829455Z","shell.execute_reply":"2022-02-24T22:07:07.835199Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\nX_train, X_test, y_train, y_test = train_test_split(train, test,\n    test_size=0.2, shuffle = True, random_state = 8)\n\n\n# step 1\nfilenames = tf.constant(['im_01.jpg', 'im_02.jpg', 'im_03.jpg', 'im_04.jpg'])\nlabels = tf.constant([0, 1, 0, 1])\n\n# step 2: create a dataset returning slices of `filenames`\ndataset = tf.data.Dataset.from_tensor_slices((filenames, labels))\n\n# step 3: parse every image in the dataset using `map`\ndef _parse_function(filename, label):\n    image_string = tf.read_file(filename)\n    image_decoded = tf.image.decode_jpeg(image_string, channels=3)\n    image = tf.cast(image_decoded, tf.float32)\n    return image, label\n\ndataset = dataset.map(_parse_function)\ndataset = dataset.batch(2)\n\n# step 4: create iterator and final input tensor\niterator = dataset.make_one_shot_iterator()\nimages, labels = iterator.get_next()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2022-02-24T22:07:51.497972Z","iopub.execute_input":"2022-02-24T22:07:51.498736Z","iopub.status.idle":"2022-02-24T22:07:51.524298Z","shell.execute_reply.started":"2022-02-24T22:07:51.498687Z","shell.execute_reply":"2022-02-24T22:07:51.523379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"normalization_layer = tf.keras.layers.Rescaling(1./255)\nnormalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\nimage_batch, labels_batch = next(iter(normalized_ds))\nfirst_image = image_batch[0]\n# Notice the pixel values are now in `[0,1]`.\nprint(np.min(first_image), np.max(first_image))","metadata":{"execution":{"iopub.status.busy":"2022-02-24T17:22:16.916938Z","iopub.execute_input":"2022-02-24T17:22:16.917217Z","iopub.status.idle":"2022-02-24T17:22:23.36376Z","shell.execute_reply.started":"2022-02-24T17:22:16.917189Z","shell.execute_reply":"2022-02-24T17:22:23.362805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# step 1\nfilenames = tf.constant(['im_01.jpg', 'im_02.jpg', 'im_03.jpg', 'im_04.jpg'])\nlabels = tf.constant([0, 1, 0, 1])\n\n# step 2: create a dataset returning slices of `filenames`\ndataset = tf.data.Dataset.from_tensor_slices((filenames, labels))\n\n# step 3: parse every image in the dataset using `map`\ndef _parse_function(filename, label):\n    image_string = tf.read_file(filename)\n    image_decoded = tf.image.decode_jpeg(image_string, channels=3)\n    image = tf.cast(image_decoded, tf.float32)\n    return image, label\n\ndataset = dataset.map(_parse_function)\ndataset = dataset.batch(2)\n\n# step 4: create iterator and final input tensor\niterator = dataset.make_one_shot_iterator()\nimages, labels = iterator.get_next()\n\n\n\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\n    ","metadata":{"execution":{"iopub.status.busy":"2022-02-24T21:26:30.747778Z","iopub.execute_input":"2022-02-24T21:26:30.74866Z","iopub.status.idle":"2022-02-24T21:26:30.80587Z","shell.execute_reply.started":"2022-02-24T21:26:30.748613Z","shell.execute_reply":"2022-02-24T21:26:30.80518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2022-02-24T20:15:26.179644Z","iopub.execute_input":"2022-02-24T20:15:26.180084Z","iopub.status.idle":"2022-02-24T20:15:26.186338Z","shell.execute_reply.started":"2022-02-24T20:15:26.180028Z","shell.execute_reply":"2022-02-24T20:15:26.185519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2022-02-24T20:15:34.500492Z","iopub.execute_input":"2022-02-24T20:15:34.500989Z","iopub.status.idle":"2022-02-24T20:15:35.170217Z","shell.execute_reply.started":"2022-02-24T20:15:34.500951Z","shell.execute_reply":"2022-02-24T20:15:35.169435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load and preprocess images\nimport numpy as np\nfrom numpy import asarray\nimport os\nimport PIL\nfrom PIL import Image\nimport tensorflow as tf\nimport tensorflow_datasets as tfds\nimport glob\nfrom matplotlib import pyplot\n\nAircraft_Carrier = []\nfor filename in glob.glob('../input/vehicleImage/vehicles/Aircraft_Carrier/*.JPEG'): #assuming JPEG\n    # load the image and resize\n    im=Image.open(filename).resize((500,500))\n    imRGB=im.convert('RGB')\n    # convert image to numpy array\n    imdata = asarray(imRGB)\n    Aircraft_Carrier.append(imdata)\n\n# summarize shape\nprint(Aircraft_Carrier[0].shape)\nprint(Aircraft_Carrier[1].shape)\nprint(Aircraft_Carrier[2].shape)\nprint(Aircraft_Carrier[3].shape)\n\npyplot.imshow(Aircraft_Carrier[0])\npyplot.show()\npyplot.imshow(Aircraft_Carrier[1])\npyplot.show()\npyplot.imshow(Aircraft_Carrier[2])\npyplot.show()\n\n\n# step 1\nfilenames = tf.constant(Aircraft_Carrier)\nlabels = tf.constant([0, 1, 0, 1])\n\n# step 1\nfilenames = tf.constant(['im_01.jpg', 'im_02.jpg', 'im_03.jpg', 'im_04.jpg'])\nlabels = tf.constant([0, 1, 0, 1])\n\n# step 2: create a dataset returning slices of `filenames`\ndataset = tf.data.Dataset.from_tensor_slices((filenames, labels))\n\n# step 3: parse every image in the dataset using `map`\ndef _parse_function(filename, label):\n    image_string = tf.read_file(filename)\n    image_decoded = tf.image.decode_jpeg(image_string, channels=3)\n    image = tf.cast(image_decoded, tf.float32)\n    return image, label\n\ndataset = dataset.map(_parse_function)\ndataset = dataset.batch(2)\n\n# step 4: create iterator and final input tensor\niterator = dataset.make_one_shot_iterator()\nimages, labels = iterator.get_next()\n\n\nnormalization_layer = tf.keras.layers.Rescaling(1./255)\nnormalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\nimage_batch, labels_batch = next(iter(normalized_ds))\nfirst_image = image_batch[0]\n# Notice the pixel values are now in `[0,1]`.\nprint(np.min(first_image), np.max(first_image))\n\n\n\n\n\n\n\n\n\n\n\n\n\nAircraft_Carrier = []\nfor filename in glob.glob('../input/vehicleImage/vehicles/Aircraft_Carrier/*.JPEG'): #assuming JPEG\n    # load the image and resize\n\n    image_string = tf.read_file(filename)\n    image_decoded = tf.image.decode_jpeg(image_string, channels=3)\n    image = tf.cast(image_decoded, tf.float32)\n    Aircraft_Carrier.append(image)\n      \n    \n\nfor dirnames in os.walk('../input/vehicleImage/vehicles'):\n    for dirname in dirnames:\n        print(os.path.basename(dirname))\n\n\n\n","metadata":{},"execution_count":null,"outputs":[]}]}